<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ravi's Portfolio</title>
    <link rel="stylesheet" href="../style.css">
    <style>
        header nav.container{display:flex;justify-content:space-between;align-items:center;padding:20px 0}
        .brand h1{font-size:1.4rem;margin:0}
        .tagline{margin:0;font-size:0.95rem}
        .social-icons{display:flex;gap:12px;align-items:center}
        .social-icons svg{width:28px;height:28px;fill:currentColor}
    </style>
</head>
<body>
    <header>
        <nav class="container">
            <div class="brand">
                <h1>Master Thesis — Multivariate Volume Rendering</h1>
                <p class="tagline">Rendering highly multivariate volumetric datasets</p>
            </div>
            <div class="social-icons">
                <a href="https://github.com/Rsnelllenberg" title="GitHub" target="_blank" rel="noopener">
                    <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M12 .5C5.73.5.5 5.73.5 12c0 5.08 3.29 9.39 7.86 10.91.58.11.79-.25.79-.56 0-.28-.01-1.02-.02-2-3.2.7-3.88-1.54-3.88-1.54-.53-1.34-1.3-1.7-1.3-1.7-1.06-.73.08-.72.08-.72 1.17.08 1.79 1.2 1.79 1.2 1.04 1.78 2.73 1.27 3.4.97.11-.76.41-1.27.74-1.56-2.55-.29-5.23-1.28-5.23-5.7 0-1.26.45-2.29 1.19-3.1-.12-.3-.52-1.52.11-3.17 0 0 .97-.31 3.18 1.18a11.07 11.07 0 0 1 2.9-.39c.98 0 1.97.13 2.9.39 2.2-1.5 3.17-1.18 3.17-1.18.63 1.65.23 2.87.11 3.17.74.81 1.19 1.84 1.19 3.1 0 4.43-2.69 5.41-5.25 5.69.42.36.8 1.07.8 2.15 0 1.55-.01 2.8-.01 3.18 0 .31.21.68.8.56A10.52 10.52 0 0 0 23.5 12C23.5 5.73 18.27.5 12 .5z"></path></svg>
                </a>
                <a href="https://www.linkedin.com/in/rsnelllenberg" title="LinkedIn" target="_blank" rel="noopener">
                    <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M4.98 3.5a2.5 2.5 0 11.02 0H5a2.5 2.5 0 010 5h-.02A2.5 2.5 0 014.98 3.5zM3 9h4v12H3zM9 9h3.8v1.6h.1c.5-.9 1.7-1.8 3.4-1.8 3.6 0 4.3 2.4 4.3 5.5V21H16v-5.1c0-1.2 0-2.8-1.7-2.8-1.7 0-2 1.4-2 2.7V21H9V9z"></path></svg>
                </a>
                <a href="../assets/Rsnelllenberg_CV.pdf" title="CV" target="_blank" rel="noopener">
                    <svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6a2 2 0 00-2 2v16a2 2 0 002 2h12a2 2 0 002-2V8l-6-6zm1 7V3.5L20.5 9H15zM8 13h8v2H8v-2zm0 4h8v2H8v-2z"></path></svg>
                </a>
            </div>
        </nav>
    </header>

    <main class="container">
        <a href="../index.html" class="back-link">← Back to Projects</a>
        
        <article class="project-detail">
            <img src="../assets/images/master_thesis.png" alt="Master Thesis" class="project-image-large" onerror="this.src='https://via.placeholder.com/1200x600/333/ffffff?text=Master+Thesis'">

            <div class="project-meta">
                <strong>Category:</strong> Research / Volume Rendering | <strong>Year:</strong> 2025
            </div>

            <h2>Overview</h2>
            <p>
                <b>TLDR:</b> 
                I developed a method for direct volume rendering of highly multivariate volumetric datasets, so datasets where each voxel does not store just a single value (scalar field) but many values (multi-attribute or multivariate field).
                The main challenge here is not changing the math or making it run in real time on the computer (though there are also some challenges there as these datasets can get very large, think hundreds of dimensions per voxel, and more than a terrabyte in size but this was not my main focus) 
                but rather how to design transfer functions (how the user interacts with the data) in such a way that it can still explore the data and find intresting connections between multiple variables, and at the same time not user unfriendly.
            </p>
            <p>
                <b>ABSTRACT:</b>

                Standard direct volume rendering (DVR) techniques are designed for scalar data and rely on transfer functions (TFs)
                that map scalar values to color and opacity. When a voxel contains many variables (multivariate volumetric data),
                defining TFs that expose relevant structure becomes difficult, especially when datasets have dozens or hundreds of
                dimensions, such as CycIF and other high-dimensional bio-medical volumes.
            </p>
            <p>
                Common multi-dimensional workarounds — assigning hues to individual dimensions or using parallel-coordinate/star
                plots — either provide limited expressivity or do not scale cleanly. A promising alternative is to apply
                neighborhood-preserving dimensionality reduction (DR) such as t-SNE or UMAP to reduce the high-dimensional data to
                a low-dimensional embedding and design TFs in that embedded space. This lets users leverage familiar 2D TF
                interfaces while preserving local similarity relationships that are meaningful for exploration and analysis.
            </p>
            <p>
                However, t-SNE and UMAP are nonlinear: interpolating in the embedded space does not trivially correspond to
                interpolated high-dimensional values, which is a problem for DVR sampling and reconstruction. In my thesis I
                designed and evaluated multiple interpolation strategies to address this: the most accurate approach uses
                approximate nearest neighbor (ANN) lookups to approximate where an interpolated high-dimensional sample would
                fall in the embedding. I also propose an adapted two-step transfer function that enables gradient-like opacity and
                surface shading effects for multivariate data — effects that scalar TFs provide but that are not directly
                available for high-dimensional data.
            </p>
            <p>
                The methods were implemented and evaluated on CycIF datasets as part of the Bio+MedVis 2025 challenge. The work
                demonstrates a very high-fidelity rendering method (used for final-quality outputs) and a hybrid interaction
                workflow pairing that method with faster approximations to maintain interactivity.
            </p>
            <h3>Implementation & Skills</h3>
            <p>
                The project is a full research-to-prototype effort. I implemented a plugin for the ManiVault framework and a
                stand-alone application featuring an interactive Qt-based UI. The rendering pipeline is implemented in OpenGL and
                relies on extensive GLSL shader programming; though some rendermodes use compute shaders. This project combined rigorous research (literature
                review, algorithm design, evaluation) with engineering: C++ development, UI design (Qt), OpenGL/GLSL.
            </p>
            <p>
                The end result is a usable tool for exploring multivariate volumes that balances visual fidelity with
                interactive performance, and which served as the basis for the publication and demo linked below.
            </p>

            <h2>Paper & Resources</h2>
            <p>
                For details see the publication: <a href="https://publications.graphics.tudelft.nl/papers/831" target="_blank" rel="noopener"> Ravi Snellenberg and Thomas Höllt, t-SNE based Transfer Functions for Multi-attribute Volume Rendering, Challenge entry for the Bio+MedVis Challenge at IEEE VIS, 2025.</a>
            </p>
            <p>
                For code see the github: <a href="https://github.com/Rsnelllenberg/VolumeProjectorPlugin" target="_blank" rel="noopener"> Link to the github repository: https://github.com/Rsnelllenberg/VolumeProjectorPlugin</a>
            </p>

            <h2>Video</h2>
            <p>
                Demonstration video:
            </p>
            <video controls width="100%" preload="metadata">
                <source src="https://github.com/user-attachments/assets/a50c668d-30e0-4cd2-a6c8-6574041d27f9" type="video/mp4">
                Your browser does not support the video tag.
            </video>

            <h2>Technologies Used</h2>
            <div class="tech-stack">
                <span class="tech-tag">C++</span>
                <span class="tech-tag">Qt</span>
                <span class="tech-tag">OpenGL</span>
                <span class="tech-tag">Volume Rendering</span>
                <span class="tech-tag">Data Visualization</span>
                <span class="tech-tag">Research Methods</span>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 My Portfolio. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
